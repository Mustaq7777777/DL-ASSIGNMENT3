{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2KNrt+UPk4sYqAYzhJSpp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mustaq7777777/DL-ASSIGNMENT3/blob/main/DL_Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup and Imports"
      ],
      "metadata": {
        "id": "DUXqOGN6GO0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing all necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as func\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import wandb\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# For reproducibility\n",
        "def seed_everything(seed=42):\n",
        "    \"\"\"Set random seed for all major libraries\"\"\"\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "\n",
        "# Set seed for reproducibility\n",
        "seed_everything(42)\n",
        "\n",
        "# Device selection: CPU or GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "KAJ4FenEGJkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading and Extracting the Dakshina Dataset"
      ],
      "metadata": {
        "id": "CW37qPkIGeIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the Dakshina dataset\n",
        "!yes | wget \"https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\"\n",
        "\n",
        "# Extract the downloaded tar file\n",
        "!yes | tar xopf dakshina_dataset_v1.0.tar"
      ],
      "metadata": {
        "id": "i7fxSiDbGkHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Loading and Processing Functions"
      ],
      "metadata": {
        "id": "nGb1w7TGGo9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_tsv(file_path):\n",
        "    \"\"\"Read a tab-separated file with source and target text\"\"\"\n",
        "    eng_words = []\n",
        "    tel_words = []\n",
        "    with open(file_path, encoding='utf-8') as f:\n",
        "        for ln in f:\n",
        "            parts = ln.strip().split('\\t')\n",
        "            if len(parts) >= 2:\n",
        "                tel_words.append(parts[0])  # Dakshina format has target first\n",
        "                eng_words.append(parts[1])  # Source (English) second\n",
        "    return eng_words, tel_words\n",
        "\n",
        "def load_dakshina_data(language='tel', base_path=None):\n",
        "    \"\"\"Load transliteration data from Dakshina TSV files\"\"\"\n",
        "    if base_path is None:\n",
        "        # Default path structure for Dakshina\n",
        "        base_path = os.path.join(\n",
        "            '/kaggle/working/dakshina_dataset_v1.0',\n",
        "            language, 'lexicons'\n",
        "        )\n",
        "\n",
        "    # Paths to data files\n",
        "    train_file = os.path.join(base_path, f\"{language}.translit.sampled.train.tsv\")\n",
        "    valid_file = os.path.join(base_path, f\"{language}.translit.sampled.dev.tsv\")\n",
        "    test_file = os.path.join(base_path, f\"{language}.translit.sampled.test.tsv\")\n",
        "\n",
        "    # Load data\n",
        "    eng_list_train, tel_list_train = read_tsv(train_file)\n",
        "    eng_list_valid, tel_list_valid = read_tsv(valid_file)\n",
        "    eng_list_test, tel_list_test = read_tsv(test_file)\n",
        "\n",
        "    # Build vocabularies\n",
        "    eng_vocab = []\n",
        "    tel_vocab = []\n",
        "    max_eng_len = -1\n",
        "    max_tel_len = -1\n",
        "    max_eng_word = \"\"\n",
        "    max_tel_word = \"\"\n",
        "\n",
        "    # Process training data for vocabulary\n",
        "    for word in eng_list_train:\n",
        "        max_eng_len = max(max_eng_len, len(word))\n",
        "        if max_eng_len == len(word):\n",
        "            max_eng_word = word\n",
        "        for letter in word:\n",
        "            eng_vocab.append(letter)\n",
        "    eng_vocab = list(set(eng_vocab))\n",
        "    eng_vocab.sort()\n",
        "\n",
        "    for word in tel_list_train:\n",
        "        max_tel_len = max(max_tel_len, len(word))\n",
        "        if max_tel_len == len(word):\n",
        "            max_tel_word = word\n",
        "        for letter in word:\n",
        "            tel_vocab.append(letter)\n",
        "    tel_vocab = list(set(tel_vocab))\n",
        "    tel_vocab.sort()\n",
        "\n",
        "    # Update max lengths from validation and test sets\n",
        "    for word in eng_list_valid:\n",
        "        max_eng_len = max(max_eng_len, len(word))\n",
        "    for word in eng_list_test:\n",
        "        max_eng_len = max(max_eng_len, len(word))\n",
        "    for word in tel_list_test:\n",
        "        max_tel_len = max(max_tel_len, len(word))\n",
        "    for word in tel_list_valid:\n",
        "        max_tel_len = max(max_tel_len, len(word))\n",
        "\n",
        "    #printing the values to know about data\n",
        "\n",
        "    print(f\"English vocabulary size: {len(eng_vocab)}\")\n",
        "    print(f\"Target language vocabulary size: {len(tel_vocab)}\")\n",
        "    print(f\"Max English length: {max_eng_len}\")\n",
        "    print(f\"Max target language length: {max_tel_len}\")\n",
        "    print(f\"Training examples: {len(eng_list_train)}\")\n",
        "\n",
        "    return (eng_list_train, tel_list_train, eng_list_valid, tel_list_valid,\n",
        "            eng_list_test, tel_list_test, eng_vocab, tel_vocab,\n",
        "            max_eng_len, max_tel_len)"
      ],
      "metadata": {
        "id": "iMSCOBPhGuMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Vectorization"
      ],
      "metadata": {
        "id": "wUZYrM5KG-vM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word_to_vector(language, word, eng_vocab, tel_vocab, max_eng_len, max_tel_len):\n",
        "    \"\"\"Convert a word to its vectorial representation\"\"\"\n",
        "    vec = []\n",
        "    if language == \"english\":\n",
        "        # Start token\n",
        "        vec.append(len(eng_vocab) + 1)\n",
        "        # Word content\n",
        "        for letter in word:\n",
        "            for albt in range(len(eng_vocab)):\n",
        "                if eng_vocab[albt] == letter:\n",
        "                    vec.append(albt + 1)\n",
        "        # Padding\n",
        "        while len(vec) < (max_eng_len + 1):\n",
        "            vec.append(0)\n",
        "        # End token\n",
        "        vec.append(0)\n",
        "    else:\n",
        "        # Start token\n",
        "        vec.append(len(tel_vocab) + 1)\n",
        "        # Word content\n",
        "        for letter in word:\n",
        "            for albt in range(len(tel_vocab)):\n",
        "                if tel_vocab[albt] == letter:\n",
        "                    vec.append(albt + 1)\n",
        "        # Padding\n",
        "        while len(vec) < (max_tel_len + 1):\n",
        "            vec.append(0)\n",
        "        # End token\n",
        "        vec.append(0)\n",
        "    return vec\n",
        "\n",
        "def prepare_matrices(eng_list, tel_list, eng_vocab, tel_vocab, max_eng_len, max_tel_len):\n",
        "    \"\"\"Create tensor matrices from word lists\"\"\"\n",
        "    eng_matrix = []\n",
        "    tel_matrix = []\n",
        "\n",
        "    for word in eng_list:\n",
        "        eng_matrix.append(word_to_vector(\"english\", word, eng_vocab, tel_vocab, max_eng_len, max_tel_len))\n",
        "\n",
        "    for word in tel_list:\n",
        "        tel_matrix.append(word_to_vector(\"telugu\", word, eng_vocab, tel_vocab, max_eng_len, max_tel_len))\n",
        "\n",
        "    return torch.tensor(eng_matrix), torch.tensor(tel_matrix)"
      ],
      "metadata": {
        "id": "6tbXY6_5HDXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading data"
      ],
      "metadata": {
        "id": "QDq3O1WlHaG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "data = load_dakshina_data('tel')\n",
        "(eng_list_train, tel_list_train, eng_list_valid, tel_list_valid,\n",
        " eng_list_test, tel_list_test, eng_vocab, tel_vocab,\n",
        " max_eng_len, max_tel_len) = data\n",
        "\n",
        "# Prepare matrices\n",
        "eng_matrix_train, tel_matrix_train = prepare_matrices(\n",
        "    eng_list_train, tel_list_train, eng_vocab, tel_vocab, max_eng_len, max_tel_len\n",
        ")\n",
        "\n",
        "eng_matrix_valid, tel_matrix_valid = prepare_matrices(\n",
        "    eng_list_valid, tel_list_valid, eng_vocab, tel_vocab, max_eng_len, max_tel_len\n",
        ")\n",
        "\n",
        "eng_matrix_test, tel_matrix_test = prepare_matrices(\n",
        "    eng_list_test, tel_list_test, eng_vocab, tel_vocab, max_eng_len, max_tel_len\n",
        ")\n",
        "\n",
        "print(f\"Training matrices shape: English {eng_matrix_train.shape}, Telugu {tel_matrix_train.shape}\")\n",
        "print(f\"Validation matrices shape: English {eng_matrix_valid.shape}, Telugu {tel_matrix_valid.shape}\")\n",
        "print(f\"Test matrices shape: English {eng_matrix_test.shape}, Telugu {tel_matrix_test.shape}\")"
      ],
      "metadata": {
        "id": "rZD6ynjXHcIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoder"
      ],
      "metadata": {
        "id": "jiigX8xiHt60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, enc_layers, hidden_size,\n",
        "                 cell_type, bi_directional_bit, dropout, batch_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.enc_layers = enc_layers\n",
        "        self.cell_type = cell_type\n",
        "        self.bi_directional_bit = bi_directional_bit\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # Initialize RNN based on cell type\n",
        "        if cell_type == \"RNN\":\n",
        "            self.rnn = nn.RNN(embedding_size, hidden_size, enc_layers,\n",
        "                             dropout=dropout, bidirectional=bi_directional_bit)\n",
        "        elif cell_type == \"GRU\":\n",
        "            self.gru = nn.GRU(embedding_size, hidden_size, enc_layers,\n",
        "                             dropout=dropout, bidirectional=bi_directional_bit)\n",
        "        else:  # LSTM\n",
        "            self.lstm = nn.LSTM(embedding_size, hidden_size, enc_layers,\n",
        "                               dropout=dropout, bidirectional=bi_directional_bit)\n",
        "\n",
        "    def forward(self, x, hidden, cell):\n",
        "        \"\"\"Forward pass through the encoder\"\"\"\n",
        "        # Apply embedding and reshape\n",
        "        embedding = self.embedding(x).view(-1, self.batch_size, self.embedding_size)\n",
        "\n",
        "        # Pass through the appropriate RNN type\n",
        "        if self.cell_type == \"RNN\":\n",
        "            output, hidden = self.rnn(embedding, hidden)\n",
        "        elif self.cell_type == \"GRU\":\n",
        "            output, hidden = self.gru(embedding, hidden)\n",
        "        else:  # LSTM\n",
        "            output, (hidden, cell) = self.lstm(embedding, (hidden, cell))\n",
        "            return output, hidden, cell\n",
        "\n",
        "        return output, hidden\n",
        "\n",
        "    def initialize_hidden(self):\n",
        "        \"\"\"Initialize hidden state tensor\"\"\"\n",
        "        if self.bi_directional_bit:\n",
        "            return torch.zeros(2 * self.enc_layers, self.batch_size,\n",
        "                               self.hidden_size, device=device)\n",
        "        return torch.zeros(self.enc_layers, self.batch_size,\n",
        "                           self.hidden_size, device=device)\n",
        "\n",
        "    def initialize_cell(self):\n",
        "        \"\"\"Initialize cell state tensor (for LSTM)\"\"\"\n",
        "        if self.bi_directional_bit:\n",
        "            return torch.zeros(2 * self.enc_layers, self.batch_size,\n",
        "                               self.hidden_size, device=device)\n",
        "        return torch.zeros(self.enc_layers, self.batch_size,\n",
        "                           self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "DRfk2zZLHuMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bahdanau Attention Mechanism"
      ],
      "metadata": {
        "id": "EwivfYuvH1Gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear(enc_hid_dim + dec_hid_dim, dec_hid_dim)\n",
        "        self.v = nn.Linear(dec_hid_dim, 1, bias=False)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        # hidden: [batch_size, dec_hid_dim]\n",
        "        # encoder_outputs: [src_len, batch_size, enc_hid_dim]\n",
        "\n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "\n",
        "        # Repeat hidden for src_len times\n",
        "        # [batch_size, dec_hid_dim] -> [batch_size, src_len, dec_hid_dim]\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "\n",
        "        # Transpose encoder outputs for attention calculation\n",
        "        # [src_len, batch_size, enc_hid_dim] -> [batch_size, src_len, enc_hid_dim]\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        # Calculate attention scores\n",
        "        # [batch_size, src_len, enc_hid_dim + dec_hid_dim] -> [batch_size, src_len, dec_hid_dim]\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
        "\n",
        "        # [batch_size, src_len, dec_hid_dim] -> [batch_size, src_len, 1]\n",
        "        attention = self.v(energy)\n",
        "\n",
        "        # [batch_size, src_len, 1] -> [batch_size, src_len]\n",
        "        attention = attention.squeeze(2)\n",
        "\n",
        "        # Apply softmax to get attention weights\n",
        "        # [batch_size, src_len]\n",
        "        return func.softmax(attention, dim=1)"
      ],
      "metadata": {
        "id": "hGxptHPQH85F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoder (without attention)"
      ],
      "metadata": {
        "id": "rGGHE1z1IFRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, dec_layers,\n",
        "                 dropout, cell_type, output_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dec_layers = dec_layers\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.cell_type = cell_type\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "\n",
        "        # Initialize RNN based on cell type\n",
        "        if cell_type == \"RNN\":\n",
        "            self.rnn = nn.RNN(embedding_size, hidden_size, dec_layers, dropout=dropout)\n",
        "        elif cell_type == \"GRU\":\n",
        "            self.gru = nn.GRU(embedding_size, hidden_size, dec_layers, dropout=dropout)\n",
        "        else:  # LSTM\n",
        "            self.lstm = nn.LSTM(embedding_size, hidden_size, dec_layers, dropout=dropout)\n",
        "\n",
        "        # Output projection\n",
        "        self.fully_conc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, prev_output, prev_hidden, cell=0):\n",
        "        \"\"\"Forward pass through the decoder\"\"\"\n",
        "        # Reshape input token and apply embedding\n",
        "        x = x.unsqueeze(0).int()\n",
        "        embedding = self.embedding(x)\n",
        "        embedding = self.dropout(embedding)\n",
        "\n",
        "        # Pass through the appropriate RNN type\n",
        "        if self.cell_type == \"RNN\":\n",
        "            outputs, hidden = self.rnn(embedding, prev_hidden)\n",
        "        elif self.cell_type == \"GRU\":\n",
        "            outputs, hidden = self.gru(embedding, prev_hidden)\n",
        "        else:  # LSTM\n",
        "            outputs, (hidden, cell) = self.lstm(embedding, (prev_hidden, cell))\n",
        "\n",
        "        # Project to vocabulary size\n",
        "        pred = self.fully_conc(outputs)\n",
        "        pred = pred.squeeze(0)  # Remove sequence dimension\n",
        "\n",
        "        if self.cell_type == \"GRU\" or self.cell_type == \"RNN\":\n",
        "            return pred, hidden\n",
        "\n",
        "        return pred, hidden, cell"
      ],
      "metadata": {
        "id": "O9jkmF96IJqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoder(with Attention)"
      ],
      "metadata": {
        "id": "kKlKC5FfuYoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionDecoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size,\n",
        "                 cell_type, dec_layers, dropout, bi_directional_bit):\n",
        "        super(AttentionDecoder, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.cell_type = cell_type\n",
        "        self.dec_layers = dec_layers\n",
        "        self.bi_directional_bit = bi_directional_bit\n",
        "        self.embedding_size = embedding_size\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "\n",
        "        # Attention mechanism\n",
        "        self.attention = BahdanauAttention(hidden_size, hidden_size)\n",
        "\n",
        "        # RNN input dimension (embedding + context)\n",
        "        self.rnn_input_dim = embedding_size + hidden_size\n",
        "\n",
        "        # Initialize RNN based on cell type\n",
        "        if cell_type == \"LSTM\":\n",
        "            self.lstm = nn.LSTM(self.rnn_input_dim, hidden_size, dec_layers, dropout=dropout)\n",
        "        elif cell_type == \"GRU\":\n",
        "            self.gru = nn.GRU(self.rnn_input_dim, hidden_size, dec_layers, dropout=dropout)\n",
        "        else:  # RNN\n",
        "            self.rnn = nn.RNN(self.rnn_input_dim, hidden_size, dec_layers, dropout=dropout)\n",
        "\n",
        "        # Output projection (combines hidden state, context vector, and embedding)\n",
        "        self.fully_conc = nn.Linear(hidden_size + hidden_size + embedding_size, output_size)\n",
        "\n",
        "    def forward(self, x, encoder_outputs, prev_hidden, cell=0):\n",
        "        \"\"\"Forward pass with attention mechanism\"\"\"\n",
        "        # Get the last layer's hidden state\n",
        "        if self.cell_type == 'LSTM':\n",
        "            attention_hidden = prev_hidden[0][-1]\n",
        "        else:\n",
        "            attention_hidden = prev_hidden[-1]\n",
        "\n",
        "        # Calculate attention weights\n",
        "        attn_weights = self.attention(attention_hidden, encoder_outputs)\n",
        "\n",
        "        # Create context vector by applying attention weights to encoder outputs\n",
        "        # [batch_size, src_len] -> [batch_size, 1, src_len]\n",
        "        attn_weights = attn_weights.unsqueeze(1)\n",
        "\n",
        "        # [src_len, batch_size, enc_hid_dim] -> [batch_size, src_len, enc_hid_dim]\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        # [batch_size, 1, src_len] x [batch_size, src_len, enc_hid_dim] -> [batch_size, 1, enc_hid_dim]\n",
        "        context = torch.bmm(attn_weights, encoder_outputs)\n",
        "\n",
        "        # Embed input token\n",
        "        x = x.unsqueeze(0)  # Add sequence dimension\n",
        "        embedded = self.embedding(x)\n",
        "\n",
        "        # Combine embedding and context for RNN input\n",
        "        # [1, batch_size, emb_dim], [batch_size, 1, enc_hid_dim] -> [1, batch_size, emb_dim + enc_hid_dim]\n",
        "        rnn_input = torch.cat((embedded, context.permute(1, 0, 2)), dim=2)\n",
        "\n",
        "        # Pass through the appropriate RNN type\n",
        "        if self.cell_type == \"RNN\":\n",
        "            outputs, hidden = self.rnn(rnn_input, prev_hidden)\n",
        "        elif self.cell_type == \"GRU\":\n",
        "            outputs, hidden = self.gru(rnn_input, prev_hidden)\n",
        "        else:  # LSTM\n",
        "            outputs, (hidden, cell) = self.lstm(rnn_input, (prev_hidden, cell))\n",
        "\n",
        "        # For output projection, combine hidden state, context, and embedded input\n",
        "        outputs = outputs.squeeze(0)  # Remove sequence dimension\n",
        "        embedded = embedded.squeeze(0)  # Remove sequence dimension\n",
        "        context = context.squeeze(1)   # Remove extra dimension\n",
        "\n",
        "        # Project to vocabulary size\n",
        "        pred = self.fully_conc(torch.cat((outputs, context, embedded), dim=1))\n",
        "\n",
        "        if self.cell_type == \"GRU\" or self.cell_type == \"RNN\":\n",
        "            return pred, hidden\n",
        "        else:\n",
        "            return pred, hidden, cell"
      ],
      "metadata": {
        "id": "vXUuiPGHuccv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seq 2 Seq Model"
      ],
      "metadata": {
        "id": "sltUGxerugua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, decoder, encoder, cell_type, bidirectional_bit,\n",
        "                 encoder_layers, decoder_layers):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.decoder = decoder\n",
        "        self.encoder = encoder\n",
        "        self.cell_type = cell_type\n",
        "        self.bidirectional_bit = bidirectional_bit\n",
        "        self.encoder_layers = encoder_layers\n",
        "        self.decoder_layers = decoder_layers\n",
        "\n",
        "    def forward(self, input_seq, target, teacher_force_ratio=0.5):\n",
        "        \"\"\"Forward pass through the sequence-to-sequence model\"\"\"\n",
        "        batch_size = input_seq.shape[1]\n",
        "        tar_seq_length = target.shape[0]\n",
        "        final_target_vocab_size = self.decoder.output_size\n",
        "\n",
        "        # Initialize outputs tensor\n",
        "        outputs = torch.zeros(tar_seq_length, batch_size,\n",
        "                             final_target_vocab_size).to(device=device)\n",
        "\n",
        "        # Initialize encoder states\n",
        "        hidden = self.encoder.initialize_hidden()\n",
        "        cell = self.encoder.initialize_cell()\n",
        "\n",
        "        # Encode input sequence\n",
        "        if self.cell_type == \"RNN\" or self.cell_type == \"GRU\":\n",
        "            encoder_output, hidden = self.encoder(input_seq, hidden, cell)\n",
        "        else:  # LSTM\n",
        "            encoder_output, hidden, cell = self.encoder(input_seq, hidden, cell)\n",
        "\n",
        "        # Handle bidirectional encoder or different layer counts\n",
        "        if self.decoder_layers != self.encoder_layers or self.bidirectional_bit:\n",
        "            if self.cell_type in [\"RNN\", \"GRU\", \"LSTM\"]:\n",
        "                # Combine bidirectional hidden states if needed\n",
        "                if self.bidirectional_bit:\n",
        "                    # Sum forward and backward directions\n",
        "                    hidden_forward = hidden[:self.encoder_layers]\n",
        "                    hidden_backward = hidden[self.encoder_layers:]\n",
        "                    hidden = hidden_forward + hidden_backward\n",
        "\n",
        "                # Match decoder layers\n",
        "                if self.decoder_layers > 1 and self.encoder_layers == 1:\n",
        "                    hidden = hidden.repeat(self.decoder_layers, 1, 1)\n",
        "\n",
        "            if self.cell_type == \"LSTM\":\n",
        "                # Also handle cell states for LSTM\n",
        "                if self.bidirectional_bit:\n",
        "                    # Sum forward and backward directions\n",
        "                    cell_forward = cell[:self.encoder_layers]\n",
        "                    cell_backward = cell[self.encoder_layers:]\n",
        "                    cell = cell_forward + cell_backward\n",
        "\n",
        "                # Match decoder layers\n",
        "                if self.decoder_layers > 1 and self.encoder_layers == 1:\n",
        "                    cell = cell.repeat(self.decoder_layers, 1, 1)\n",
        "\n",
        "        # Start with first token (SOS token)\n",
        "        x = target[0]\n",
        "\n",
        "        # Generate sequence\n",
        "        for t in range(1, tar_seq_length):\n",
        "            # Process through decoder\n",
        "            if self.cell_type == \"RNN\" or self.cell_type == \"GRU\":\n",
        "                output, hidden = self.decoder(x, encoder_output, hidden)\n",
        "            else:  # LSTM\n",
        "                output, hidden, cell = self.decoder(x, encoder_output, hidden, cell)\n",
        "\n",
        "            # Store output\n",
        "            outputs[t] = output\n",
        "\n",
        "            # Teacher forcing: use target token with probability teacher_force_ratio\n",
        "            if random.random() < teacher_force_ratio:\n",
        "                x = target[t]\n",
        "            else:\n",
        "                # Otherwise use model's prediction\n",
        "                predicted = output.argmax(1)\n",
        "                x = predicted\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "8EKzU_ffus-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and Evaluation functions"
      ],
      "metadata": {
        "id": "wJDCfyj2uuRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_fun(eng_matrix, tel_matrix, batch_size, model):\n",
        "    \"\"\"Compute accuracy on a dataset\"\"\"\n",
        "    correct = 0\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_id in range(int(len(eng_matrix) / batch_size)):\n",
        "            # Get batch\n",
        "            inp_word = eng_matrix[batch_size * batch_id:batch_size * (batch_id + 1)].to(device=device)\n",
        "            out_word = tel_matrix[batch_size * batch_id:batch_size * (batch_id + 1)].to(device=device)\n",
        "\n",
        "            # Transpose for sequence-first format\n",
        "            inp_word = inp_word.T\n",
        "            out_word = out_word.T\n",
        "\n",
        "            # Forward pass with no teacher forcing\n",
        "            output = model.forward(inp_word, out_word, 0)\n",
        "\n",
        "            # Get predictions\n",
        "            output = nn.Softmax(dim=2)(output)\n",
        "            output = torch.argmax(output, dim=2)\n",
        "\n",
        "            # Transpose back to batch-first for comparison\n",
        "            output = output.T\n",
        "            out_word = out_word.T\n",
        "\n",
        "            # Count correct predictions (exact match of entire sequence)\n",
        "            for i in range(min(batch_size, len(inp_word))):  # Handle last batch which may be smaller\n",
        "                if torch.equal(output[i][1:], out_word[i][1:]):\n",
        "                    correct += 1\n",
        "\n",
        "    # Return accuracy percentage\n",
        "    return (correct * 100) / len(eng_matrix)\n",
        "\n",
        "def vectors_to_actual_words(model, eng_matrix, tel_matrix, batch_size, eng_vocab, tel_vocab, data_type):\n",
        "    \"\"\"Convert model predictions to readable words\"\"\"\n",
        "    results = []\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_id in range(int(len(eng_matrix) / batch_size)):\n",
        "            # Get batch\n",
        "            input_batch = eng_matrix[batch_id * batch_size:batch_size * (batch_id + 1)].to(device=device)\n",
        "            output_batch = tel_matrix[batch_id * batch_size:batch_size * (batch_id + 1)].to(device=device)\n",
        "\n",
        "            # Forward pass\n",
        "            model_output = model.forward(input_batch.T, output_batch.T, 0)\n",
        "            model_output = nn.Softmax(dim=2)(model_output)\n",
        "            model_output = torch.argmax(model_output, dim=2)\n",
        "            model_output = model_output.T\n",
        "\n",
        "            # Process each example\n",
        "            for idx in range(len(output_batch)):\n",
        "                res_word = output_batch[idx]\n",
        "                pred_word = model_output[idx]\n",
        "                inp_word = input_batch[idx]\n",
        "\n",
        "                # Convert to strings\n",
        "                word_res = \"\"\n",
        "                word_pred = \"\"\n",
        "                word_inp = \"\"\n",
        "\n",
        "                # Convert prediction to string\n",
        "                for i in range(len(pred_word)):\n",
        "                    if pred_word[i] > 0 and pred_word[i] < len(tel_vocab) + 1:\n",
        "                        word_pred += tel_vocab[pred_word[i] - 1]\n",
        "\n",
        "                # Convert input to string\n",
        "                for i in range(len(inp_word)):\n",
        "                    if inp_word[i] > 0 and inp_word[i] < len(eng_vocab) + 1:\n",
        "                        word_inp += eng_vocab[inp_word[i] - 1]\n",
        "\n",
        "                # Convert target to string\n",
        "                for i in range(len(res_word)):\n",
        "                    if res_word[i] > 0 and res_word[i] < len(tel_vocab) + 1:\n",
        "                        word_res += tel_vocab[res_word[i] - 1]\n",
        "\n",
        "                results.append((word_inp, word_pred, word_res))\n",
        "\n",
        "    return results\n",
        "\n",
        "def save_to_csv(results, filename):\n",
        "    \"\"\"Save results to a CSV file\"\"\"\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        f.write(\"Source,Predicted,Target\\n\")\n",
        "        for src, pred, tgt in results:\n",
        "            f.write(f\"{src},{pred},{tgt}\\n\")"
      ],
      "metadata": {
        "id": "symERFoxu15z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and Evaluating the models"
      ],
      "metadata": {
        "id": "6B_PC9aBvBkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(cell_type, bi_directional_bit, embedding_size, enc_dropout,\n",
        "                     dec_dropout, enc_layers, dec_layers, hidden_size, batch_size,\n",
        "                     attention_bit, learning_rate, max_epochs, language='tel',\n",
        "                     use_wandb=False):\n",
        "    \"\"\"Train and evaluate a seq2seq model\"\"\"\n",
        "    # Initialize wandb if requested\n",
        "    if use_wandb:\n",
        "        run_name = f\"{cell_type}_{enc_layers}l_{embedding_size}e_{hidden_size}h_\" \\\n",
        "                  f\"{'attn' if attention_bit else 'no_attn'}_\" \\\n",
        "                  f\"{'bid' if bi_directional_bit else 'uni'}\"\n",
        "\n",
        "        wandb.init(\n",
        "            project=\"DL_assignment_3\",\n",
        "            name=run_name,\n",
        "            config={\n",
        "                \"cell_type\": cell_type,\n",
        "                \"bi_directional\": bi_directional_bit,\n",
        "                \"embedding_size\": embedding_size,\n",
        "                \"enc_dropout\": enc_dropout,\n",
        "                \"dec_dropout\": dec_dropout,\n",
        "                \"enc_layers\": enc_layers,\n",
        "                \"dec_layers\": dec_layers,\n",
        "                \"hidden_size\": hidden_size,\n",
        "                \"batch_size\": batch_size,\n",
        "                \"attention\": attention_bit,\n",
        "                \"learning_rate\": learning_rate,\n",
        "                \"max_epochs\": max_epochs,\n",
        "                \"language\": language\n",
        "            }\n",
        "        )\n",
        "\n",
        "    # Get data from global variables\n",
        "    # (To keep the code structure aligned with the original)\n",
        "\n",
        "    # Model dimensions\n",
        "    enc_input_size = len(eng_vocab) + 2  # +2 for special tokens\n",
        "    dec_input_size = len(tel_vocab) + 2\n",
        "    output_size = len(tel_vocab) + 2\n",
        "\n",
        "    # Create encoder\n",
        "    encoder_section = Encoder(\n",
        "        enc_input_size, embedding_size, enc_layers, hidden_size,\n",
        "        cell_type, bi_directional_bit, enc_dropout, batch_size\n",
        "    ).to(device=device)\n",
        "\n",
        "    # Create decoder (with or without attention)\n",
        "    if attention_bit:\n",
        "        decoder_section = AttentionDecoder(\n",
        "            dec_input_size, embedding_size, hidden_size, output_size,\n",
        "            cell_type, dec_layers, dec_dropout, bi_directional_bit\n",
        "        ).to(device=device)\n",
        "    else:\n",
        "        decoder_section = Decoder(\n",
        "            dec_input_size, embedding_size, hidden_size, dec_layers,\n",
        "            dec_dropout, cell_type, output_size\n",
        "        ).to(device=device)\n",
        "\n",
        "    # Create sequence-to-sequence model\n",
        "    model = Seq2Seq(\n",
        "        decoder_section, encoder_section, cell_type,\n",
        "        bi_directional_bit, enc_layers, dec_layers\n",
        "    ).to(device=device)\n",
        "\n",
        "    # Create optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Create loss function (ignoring padding)\n",
        "    pad = len(tel_vocab) + 1\n",
        "    loss_criterion = nn.CrossEntropyLoss(ignore_index=pad)\n",
        "\n",
        "    # Main training loop\n",
        "    print(f\"Starting training for {max_epochs} epochs\")\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        print(f\"Epoch: {epoch+1}/{max_epochs}\")\n",
        "\n",
        "        # Set to training mode\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        step = 0\n",
        "\n",
        "        # Training batches with progress bar\n",
        "        batch_count = int(len(eng_matrix_train) / batch_size)\n",
        "        progress_bar = tqdm(range(batch_count), desc=f\"Training {epoch+1}\")\n",
        "\n",
        "        for batch_id in progress_bar:\n",
        "            # Get batch data\n",
        "            inp_word = eng_matrix_train[batch_size * batch_id:batch_size * (batch_id + 1)].to(device=device)\n",
        "            out_word = tel_matrix_train[batch_size * batch_id:batch_size * (batch_id + 1)].to(device=device)\n",
        "\n",
        "            # Transpose for sequence-first format\n",
        "            out_word = out_word.T\n",
        "            inp_word = inp_word.T\n",
        "\n",
        "            # Forward pass\n",
        "            output = model(inp_word, out_word)\n",
        "\n",
        "            # Calculate loss (skip first token which is SOS)\n",
        "            output = output[1:].reshape(-1, output.shape[2])\n",
        "            out_word = out_word[1:].reshape(-1)\n",
        "\n",
        "            # Zero gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Compute loss\n",
        "            loss = loss_criterion(output, out_word)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Backpropagation\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "            # Update weights\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update progress bar\n",
        "            progress_bar.set_postfix(loss=loss.item())\n",
        "            step += 1\n",
        "\n",
        "        # Calculate epoch average loss\n",
        "        avg_loss = total_loss / step\n",
        "        print(f\"Total loss: {avg_loss:.4f}\")\n",
        "\n",
        "        # Evaluate on train, validation, and test sets\n",
        "        train_acc = accuracy_fun(eng_matrix_train, tel_matrix_train, batch_size, model)\n",
        "        valid_acc = accuracy_fun(eng_matrix_valid, tel_matrix_valid, batch_size, model)\n",
        "        test_acc = accuracy_fun(eng_matrix_test, tel_matrix_test, batch_size, model)\n",
        "\n",
        "        print(f\"Train accuracy: {train_acc:.2f}%\")\n",
        "        print(f\"Valid accuracy: {valid_acc:.2f}%\")\n",
        "        print(f\"Test accuracy: {test_acc:.2f}%\")\n",
        "\n",
        "        # Log to wandb if enabled\n",
        "        if use_wandb:\n",
        "            wandb.log({\n",
        "                'epoch': epoch + 1,\n",
        "                'loss': avg_loss,\n",
        "                'train_accuracy': train_acc,\n",
        "                'valid_accuracy': valid_acc,\n",
        "                'test_accuracy': test_acc\n",
        "            })\n",
        "\n",
        "    # Generate and save predictions\n",
        "    test_results = vectors_to_actual_words(\n",
        "        model, eng_matrix_test, tel_matrix_test, batch_size,\n",
        "        eng_vocab, tel_vocab, 'Test'\n",
        "    )\n",
        "    save_to_csv(test_results, f\"predictions_{cell_type}_{attention_bit}.csv\")\n",
        "\n",
        "    # Close wandb run if used\n",
        "    if use_wandb:\n",
        "        wandb.finish()\n",
        "\n",
        "    return model, (train_acc, valid_acc, test_acc), test_results"
      ],
      "metadata": {
        "id": "jTKMKLVrvF6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the models and comparing results"
      ],
      "metadata": {
        "id": "BPZSNcZavLWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration for model without attention\n",
        "config_no_attention = {\n",
        "    'cell_type': 'GRU',\n",
        "    'bi_directional_bit': True,\n",
        "    'embedding_size': 256,\n",
        "    'enc_dropout': 0.2,\n",
        "    'dec_dropout': 0.2,\n",
        "    'enc_layers': 2,\n",
        "    'dec_layers': 2,\n",
        "    'hidden_size': 512,\n",
        "    'batch_size': 64,\n",
        "    'attention_bit': False,\n",
        "    'learning_rate': 0.001,\n",
        "    'max_epochs': 10,\n",
        "    'language': 'tel',\n",
        "    'use_wandb': False  # Set to True to log to wandb\n",
        "}\n",
        "\n",
        "# Train model without attention\n",
        "no_attention_model, no_attention_accuracies, no_attention_results = train_and_evaluate(**config_no_attention)\n",
        "\n",
        "print(\"\\nFinal results without attention:\")\n",
        "print(f\"Train accuracy: {no_attention_accuracies[0]:.2f}%\")\n",
        "print(f\"Valid accuracy: {no_attention_accuracies[1]:.2f}%\")\n",
        "print(f\"Test accuracy: {no_attention_accuracies[2]:.2f}%\")\n",
        "\n",
        "# Create a bar chart to compare accuracies\n",
        "labels = ['Train', 'Valid', 'Test']\n",
        "no_attention_accs = [no_attention_accuracies[0], no_attention_accuracies[1], no_attention_accuracies[2]]\n",
        "attention_accs = [attention_accuracies[0], attention_accuracies[1], attention_accuracies[2]]\n",
        "\n",
        "x = np.arange(len(labels))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "rects1 = ax.bar(x - width/2, no_attention_accs, width, label='Without Attention')\n",
        "rects2 = ax.bar(x + width/2, attention_accs, width, label='With Attention')\n",
        "\n",
        "ax.set_ylabel('Accuracy (%)')\n",
        "ax.set_title('Seq2Seq Model Accuracy: With vs. Without Attention')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "\n",
        "# Add value labels\n",
        "def autolabel(rects):\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate(f'{height:.2f}%',\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 3),\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "autolabel(rects1)\n",
        "autolabel(rects2)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4ptKesPIvgBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter sweep"
      ],
      "metadata": {
        "id": "7T5i6A_Qvjgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_hyperparameter_sweep(with_attention=True):\n",
        "    \"\"\"Run hyperparameter sweep with wandb\"\"\"\n",
        "    sweep_name = 'Transliteration_with_Attention' if with_attention else 'Transliteration_without_Attention'\n",
        "\n",
        "    # Define sweep configuration\n",
        "    sweep_cfg = {\n",
        "        'method': 'bayes',  # Use Bayesian optimization\n",
        "        'name': sweep_name,\n",
        "        'metric': {'name': 'val_acc', 'goal': 'maximize'},\n",
        "        'parameters': {\n",
        "            # Model architecture\n",
        "            'emb_size': {'values': [128, 256, 512]},\n",
        "            'hidden_size': {'values': [128, 256, 512, 1024]},\n",
        "            'enc_layers': {'values': [1, 2, 3, 4]},\n",
        "            'cell': {'values': ['RNN', 'GRU', 'LSTM']},\n",
        "            'bidirectional': {'values': [True, False]},  # Bidirectional encode\n",
        "\n",
        "            # Training parameters\n",
        "            'dropout': {'values': [0.0, 0.1, 0.2, 0.3, 0.5]},\n",
        "            'lr': {'values': [1e-4, 2e-4, 5e-4, 8e-4, 1e-3]},\n",
        "            'batch_size': {'values': [32, 64, 128]},\n",
        "            'epochs': {'values': [10, 15, 20]},\n",
        "            'teacher_forcing': {'values': [0.3, 0.5, 0.7, 1.0]},  # Explicit teacher forcing\n",
        "            'optimizer': {'values': ['Adam', 'NAdam']},  # Added optimizer options\n",
        "            # Reproducibility\n",
        "            'seed': {'values': [42, 43, 44, 45, 46]},  # Different seeds for robustness\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Define the objective function for sweep\n",
        "    def sweep_objective():\n",
        "        run = wandb.init()\n",
        "        config = run.config\n",
        "\n",
        "        # Set seed for reproducibility\n",
        "        seed_everything(config.seed)\n",
        "\n",
        "        # Train model with this configuration\n",
        "        train_and_evaluate(\n",
        "            config.cell,\n",
        "            config.bidirectional,\n",
        "            config.emb_size,\n",
        "            config.dropout,\n",
        "            config.dropout,\n",
        "            config.enc_layers,\n",
        "            config.enc_layers,\n",
        "            config.hidden_size,\n",
        "            config.batch_size,\n",
        "            with_attention,\n",
        "            config.lr,\n",
        "            config.epochs\n",
        "        )\n",
        "\n",
        "    # Initialize sweep\n",
        "    entity = 'cs24m045-indian-institute-of-technology-madras'  # Replace with your wandb entity\n",
        "    project = 'DA6401-Assignment-3'\n",
        "\n",
        "    # Start sweep (uncomment to run)\n",
        "    # sweep_id = wandb.sweep(sweep_cfg, entity=entity, project=project)\n",
        "    # wandb.agent(sweep_id, function=sweep_objective, count=20)\n",
        "\n",
        "# Uncomment to run hyperparameter sweeps\n",
        "# run_hyperparameter_sweep(with_attention=True)   # For attention model\n",
        "# run_hyperparameter_sweep(with_attention=False)  # For no-attention model"
      ],
      "metadata": {
        "id": "Qi8aEd1rv5vv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}