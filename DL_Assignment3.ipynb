{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAX7a6lrxq7nGZzG5cN7ot",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mustaq7777777/DL-ASSIGNMENT3/blob/main/DL_Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup and Imports"
      ],
      "metadata": {
        "id": "DUXqOGN6GO0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing all necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as func\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import wandb\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# For reproducibility\n",
        "def seed_everything(seed=42):\n",
        "    \"\"\"Set random seed for all major libraries\"\"\"\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "\n",
        "# Set seed for reproducibility\n",
        "seed_everything(42)\n",
        "\n",
        "# Device selection: CPU or GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "KAJ4FenEGJkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading and Extracting the Dakshina Dataset"
      ],
      "metadata": {
        "id": "CW37qPkIGeIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the Dakshina dataset\n",
        "!yes | wget \"https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\"\n",
        "\n",
        "# Extract the downloaded tar file\n",
        "!yes | tar xopf dakshina_dataset_v1.0.tar"
      ],
      "metadata": {
        "id": "i7fxSiDbGkHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Loading and Processing Functions"
      ],
      "metadata": {
        "id": "nGb1w7TGGo9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_tsv(file_path):\n",
        "    \"\"\"Read a tab-separated file with source and target text\"\"\"\n",
        "    eng_words = []\n",
        "    tel_words = []\n",
        "    with open(file_path, encoding='utf-8') as f:\n",
        "        for ln in f:\n",
        "            parts = ln.strip().split('\\t')\n",
        "            if len(parts) >= 2:\n",
        "                tel_words.append(parts[0])  # Dakshina format has target first\n",
        "                eng_words.append(parts[1])  # Source (English) second\n",
        "    return eng_words, tel_words\n",
        "\n",
        "def load_dakshina_data(language='tel', base_path=None):\n",
        "    \"\"\"Load transliteration data from Dakshina TSV files\"\"\"\n",
        "    if base_path is None:\n",
        "        # Default path structure for Dakshina\n",
        "        base_path = os.path.join(\n",
        "            '/kaggle/working/dakshina_dataset_v1.0',\n",
        "            language, 'lexicons'\n",
        "        )\n",
        "\n",
        "    # Paths to data files\n",
        "    train_file = os.path.join(base_path, f\"{language}.translit.sampled.train.tsv\")\n",
        "    valid_file = os.path.join(base_path, f\"{language}.translit.sampled.dev.tsv\")\n",
        "    test_file = os.path.join(base_path, f\"{language}.translit.sampled.test.tsv\")\n",
        "\n",
        "    # Load data\n",
        "    eng_list_train, tel_list_train = read_tsv(train_file)\n",
        "    eng_list_valid, tel_list_valid = read_tsv(valid_file)\n",
        "    eng_list_test, tel_list_test = read_tsv(test_file)\n",
        "\n",
        "    # Build vocabularies\n",
        "    eng_vocab = []\n",
        "    tel_vocab = []\n",
        "    max_eng_len = -1\n",
        "    max_tel_len = -1\n",
        "    max_eng_word = \"\"\n",
        "    max_tel_word = \"\"\n",
        "\n",
        "    # Process training data for vocabulary\n",
        "    for word in eng_list_train:\n",
        "        max_eng_len = max(max_eng_len, len(word))\n",
        "        if max_eng_len == len(word):\n",
        "            max_eng_word = word\n",
        "        for letter in word:\n",
        "            eng_vocab.append(letter)\n",
        "    eng_vocab = list(set(eng_vocab))\n",
        "    eng_vocab.sort()\n",
        "\n",
        "    for word in tel_list_train:\n",
        "        max_tel_len = max(max_tel_len, len(word))\n",
        "        if max_tel_len == len(word):\n",
        "            max_tel_word = word\n",
        "        for letter in word:\n",
        "            tel_vocab.append(letter)\n",
        "    tel_vocab = list(set(tel_vocab))\n",
        "    tel_vocab.sort()\n",
        "\n",
        "    # Update max lengths from validation and test sets\n",
        "    for word in eng_list_valid:\n",
        "        max_eng_len = max(max_eng_len, len(word))\n",
        "    for word in eng_list_test:\n",
        "        max_eng_len = max(max_eng_len, len(word))\n",
        "    for word in tel_list_test:\n",
        "        max_tel_len = max(max_tel_len, len(word))\n",
        "    for word in tel_list_valid:\n",
        "        max_tel_len = max(max_tel_len, len(word))\n",
        "\n",
        "    #printing the values to know about data\n",
        "\n",
        "    print(f\"English vocabulary size: {len(eng_vocab)}\")\n",
        "    print(f\"Target language vocabulary size: {len(tel_vocab)}\")\n",
        "    print(f\"Max English length: {max_eng_len}\")\n",
        "    print(f\"Max target language length: {max_tel_len}\")\n",
        "    print(f\"Training examples: {len(eng_list_train)}\")\n",
        "\n",
        "    return (eng_list_train, tel_list_train, eng_list_valid, tel_list_valid,\n",
        "            eng_list_test, tel_list_test, eng_vocab, tel_vocab,\n",
        "            max_eng_len, max_tel_len)"
      ],
      "metadata": {
        "id": "iMSCOBPhGuMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Vectorization"
      ],
      "metadata": {
        "id": "wUZYrM5KG-vM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word_to_vector(language, word, eng_vocab, tel_vocab, max_eng_len, max_tel_len):\n",
        "    \"\"\"Convert a word to its vectorial representation\"\"\"\n",
        "    vec = []\n",
        "    if language == \"english\":\n",
        "        # Start token\n",
        "        vec.append(len(eng_vocab) + 1)\n",
        "        # Word content\n",
        "        for letter in word:\n",
        "            for albt in range(len(eng_vocab)):\n",
        "                if eng_vocab[albt] == letter:\n",
        "                    vec.append(albt + 1)\n",
        "        # Padding\n",
        "        while len(vec) < (max_eng_len + 1):\n",
        "            vec.append(0)\n",
        "        # End token\n",
        "        vec.append(0)\n",
        "    else:\n",
        "        # Start token\n",
        "        vec.append(len(tel_vocab) + 1)\n",
        "        # Word content\n",
        "        for letter in word:\n",
        "            for albt in range(len(tel_vocab)):\n",
        "                if tel_vocab[albt] == letter:\n",
        "                    vec.append(albt + 1)\n",
        "        # Padding\n",
        "        while len(vec) < (max_tel_len + 1):\n",
        "            vec.append(0)\n",
        "        # End token\n",
        "        vec.append(0)\n",
        "    return vec\n",
        "\n",
        "def prepare_matrices(eng_list, tel_list, eng_vocab, tel_vocab, max_eng_len, max_tel_len):\n",
        "    \"\"\"Create tensor matrices from word lists\"\"\"\n",
        "    eng_matrix = []\n",
        "    tel_matrix = []\n",
        "\n",
        "    for word in eng_list:\n",
        "        eng_matrix.append(word_to_vector(\"english\", word, eng_vocab, tel_vocab, max_eng_len, max_tel_len))\n",
        "\n",
        "    for word in tel_list:\n",
        "        tel_matrix.append(word_to_vector(\"telugu\", word, eng_vocab, tel_vocab, max_eng_len, max_tel_len))\n",
        "\n",
        "    return torch.tensor(eng_matrix), torch.tensor(tel_matrix)"
      ],
      "metadata": {
        "id": "6tbXY6_5HDXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading data"
      ],
      "metadata": {
        "id": "QDq3O1WlHaG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "data = load_dakshina_data('tel')\n",
        "(eng_list_train, tel_list_train, eng_list_valid, tel_list_valid,\n",
        " eng_list_test, tel_list_test, eng_vocab, tel_vocab,\n",
        " max_eng_len, max_tel_len) = data\n",
        "\n",
        "# Prepare matrices\n",
        "eng_matrix_train, tel_matrix_train = prepare_matrices(\n",
        "    eng_list_train, tel_list_train, eng_vocab, tel_vocab, max_eng_len, max_tel_len\n",
        ")\n",
        "\n",
        "eng_matrix_valid, tel_matrix_valid = prepare_matrices(\n",
        "    eng_list_valid, tel_list_valid, eng_vocab, tel_vocab, max_eng_len, max_tel_len\n",
        ")\n",
        "\n",
        "eng_matrix_test, tel_matrix_test = prepare_matrices(\n",
        "    eng_list_test, tel_list_test, eng_vocab, tel_vocab, max_eng_len, max_tel_len\n",
        ")\n",
        "\n",
        "print(f\"Training matrices shape: English {eng_matrix_train.shape}, Telugu {tel_matrix_train.shape}\")\n",
        "print(f\"Validation matrices shape: English {eng_matrix_valid.shape}, Telugu {tel_matrix_valid.shape}\")\n",
        "print(f\"Test matrices shape: English {eng_matrix_test.shape}, Telugu {tel_matrix_test.shape}\")"
      ],
      "metadata": {
        "id": "rZD6ynjXHcIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoder"
      ],
      "metadata": {
        "id": "jiigX8xiHt60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, enc_layers, hidden_size,\n",
        "                 cell_type, bi_directional_bit, dropout, batch_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.enc_layers = enc_layers\n",
        "        self.cell_type = cell_type\n",
        "        self.bi_directional_bit = bi_directional_bit\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # Initialize RNN based on cell type\n",
        "        if cell_type == \"RNN\":\n",
        "            self.rnn = nn.RNN(embedding_size, hidden_size, enc_layers,\n",
        "                             dropout=dropout, bidirectional=bi_directional_bit)\n",
        "        elif cell_type == \"GRU\":\n",
        "            self.gru = nn.GRU(embedding_size, hidden_size, enc_layers,\n",
        "                             dropout=dropout, bidirectional=bi_directional_bit)\n",
        "        else:  # LSTM\n",
        "            self.lstm = nn.LSTM(embedding_size, hidden_size, enc_layers,\n",
        "                               dropout=dropout, bidirectional=bi_directional_bit)\n",
        "\n",
        "    def forward(self, x, hidden, cell):\n",
        "        \"\"\"Forward pass through the encoder\"\"\"\n",
        "        # Apply embedding and reshape\n",
        "        embedding = self.embedding(x).view(-1, self.batch_size, self.embedding_size)\n",
        "\n",
        "        # Pass through the appropriate RNN type\n",
        "        if self.cell_type == \"RNN\":\n",
        "            output, hidden = self.rnn(embedding, hidden)\n",
        "        elif self.cell_type == \"GRU\":\n",
        "            output, hidden = self.gru(embedding, hidden)\n",
        "        else:  # LSTM\n",
        "            output, (hidden, cell) = self.lstm(embedding, (hidden, cell))\n",
        "            return output, hidden, cell\n",
        "\n",
        "        return output, hidden\n",
        "\n",
        "    def initialize_hidden(self):\n",
        "        \"\"\"Initialize hidden state tensor\"\"\"\n",
        "        if self.bi_directional_bit:\n",
        "            return torch.zeros(2 * self.enc_layers, self.batch_size,\n",
        "                               self.hidden_size, device=device)\n",
        "        return torch.zeros(self.enc_layers, self.batch_size,\n",
        "                           self.hidden_size, device=device)\n",
        "\n",
        "    def initialize_cell(self):\n",
        "        \"\"\"Initialize cell state tensor (for LSTM)\"\"\"\n",
        "        if self.bi_directional_bit:\n",
        "            return torch.zeros(2 * self.enc_layers, self.batch_size,\n",
        "                               self.hidden_size, device=device)\n",
        "        return torch.zeros(self.enc_layers, self.batch_size,\n",
        "                           self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "DRfk2zZLHuMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bahdanau Attention Mechanism"
      ],
      "metadata": {
        "id": "EwivfYuvH1Gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear(enc_hid_dim + dec_hid_dim, dec_hid_dim)\n",
        "        self.v = nn.Linear(dec_hid_dim, 1, bias=False)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        # hidden: [batch_size, dec_hid_dim]\n",
        "        # encoder_outputs: [src_len, batch_size, enc_hid_dim]\n",
        "\n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "\n",
        "        # Repeat hidden for src_len times\n",
        "        # [batch_size, dec_hid_dim] -> [batch_size, src_len, dec_hid_dim]\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "\n",
        "        # Transpose encoder outputs for attention calculation\n",
        "        # [src_len, batch_size, enc_hid_dim] -> [batch_size, src_len, enc_hid_dim]\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        # Calculate attention scores\n",
        "        # [batch_size, src_len, enc_hid_dim + dec_hid_dim] -> [batch_size, src_len, dec_hid_dim]\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
        "\n",
        "        # [batch_size, src_len, dec_hid_dim] -> [batch_size, src_len, 1]\n",
        "        attention = self.v(energy)\n",
        "\n",
        "        # [batch_size, src_len, 1] -> [batch_size, src_len]\n",
        "        attention = attention.squeeze(2)\n",
        "\n",
        "        # Apply softmax to get attention weights\n",
        "        # [batch_size, src_len]\n",
        "        return func.softmax(attention, dim=1)"
      ],
      "metadata": {
        "id": "hGxptHPQH85F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoder (without attention)"
      ],
      "metadata": {
        "id": "rGGHE1z1IFRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, dec_layers,\n",
        "                 dropout, cell_type, output_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dec_layers = dec_layers\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.cell_type = cell_type\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "\n",
        "        # Initialize RNN based on cell type\n",
        "        if cell_type == \"RNN\":\n",
        "            self.rnn = nn.RNN(embedding_size, hidden_size, dec_layers, dropout=dropout)\n",
        "        elif cell_type == \"GRU\":\n",
        "            self.gru = nn.GRU(embedding_size, hidden_size, dec_layers, dropout=dropout)\n",
        "        else:  # LSTM\n",
        "            self.lstm = nn.LSTM(embedding_size, hidden_size, dec_layers, dropout=dropout)\n",
        "\n",
        "        # Output projection\n",
        "        self.fully_conc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, prev_output, prev_hidden, cell=0):\n",
        "        \"\"\"Forward pass through the decoder\"\"\"\n",
        "        # Reshape input token and apply embedding\n",
        "        x = x.unsqueeze(0).int()\n",
        "        embedding = self.embedding(x)\n",
        "        embedding = self.dropout(embedding)\n",
        "\n",
        "        # Pass through the appropriate RNN type\n",
        "        if self.cell_type == \"RNN\":\n",
        "            outputs, hidden = self.rnn(embedding, prev_hidden)\n",
        "        elif self.cell_type == \"GRU\":\n",
        "            outputs, hidden = self.gru(embedding, prev_hidden)\n",
        "        else:  # LSTM\n",
        "            outputs, (hidden, cell) = self.lstm(embedding, (prev_hidden, cell))\n",
        "\n",
        "        # Project to vocabulary size\n",
        "        pred = self.fully_conc(outputs)\n",
        "        pred = pred.squeeze(0)  # Remove sequence dimension\n",
        "\n",
        "        if self.cell_type == \"GRU\" or self.cell_type == \"RNN\":\n",
        "            return pred, hidden\n",
        "\n",
        "        return pred, hidden, cell"
      ],
      "metadata": {
        "id": "O9jkmF96IJqf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}